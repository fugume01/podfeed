import functools
import json
import os
import time
import datetime
import pytz
from xml.sax.saxutils import escape
from wsgiref.handlers import format_date_time

import jsonpickle
import requests
import podgen

from flask import abort
from flask import render_template
from flask import make_response
from flask import request

from server.parser.npr import NprParser
from server import app


CACHE_TIMEOUT = 300


def lru_cache(timeout: int, maxsize: int = 128, typed: bool = False):
    def wrapper_cache(func):
        func = functools.lru_cache(maxsize=maxsize, typed=typed)(func)
        func.delta = timeout * 10 ** 9
        func.expiration = time.monotonic_ns() + func.delta

        @functools.wraps(func)
        def wrapped_func(*args, **kwargs):
            if time.monotonic_ns() >= func.expiration:
                func.cache_clear()
                func.expiration = time.monotonic_ns() + func.delta
            return func(*args, **kwargs)

        wrapped_func.cache_info = func.cache_info
        wrapped_func.cache_clear = func.cache_clear
        return wrapped_func
    return wrapper_cache


class Cache():
    def __init__(self, key, timeout):
        self.name = key
        self.raw = None
        self.rss = None
        self.fetched = 0
        self.generated = 0
        self.timeout = timeout

    def is_expired(self):
        age = int(time.time() - self.generated)
        if age >= self.timeout:
            return True
        return False

    def set_raw(self, text):
        self.raw = text
        self.fetched = time.time()

    def set_rss(self, text):
        self.rss = text
        self.generated = time.time()

    def response(self):
        response = make_response(self.rss)
        response.headers['Content-Type'] = 'application/xml'
        expire_time = self.generated + self.timeout
        response.headers['Expires'] = format_date_time(expire_time)
        max_age = int(expire_time - time.time())
        if max_age > 0:
            response.headers['Cache-Control'] = f"public, max-age={max_age}, stale-if-error=43200"
        return response

    def load(self):
        try:
            obj = jsonpickle.decode(open(f'/dev/shm/nrfeed_{self.name}.json').read())
        except FileNotFoundError:
            return

        self.rss = obj.rss
        self.raw = obj.raw
        self.generated = obj.generated
        self.fetched = obj.fetched

    def save(self):
        srcfile = f'/dev/shm/nrfeed_{self.name}.json'
        with open(srcfile, 'w') as fd:
            fd.write(jsonpickle.encode(self))
        app.logger.debug(f"wrote cache to {srcfile}")


# Application needs to be restarted if feeds.json changes
@functools.lru_cache
def get_feeds():
    return json.load(open(os.path.join(app.root_path, 'feeds.json')))


# One request per minute per URL. If there is a bug we don't want to kill the remote server.
@lru_cache(60)
def get_source_url(url):
    return requests.get(url, timeout=5)


def generate_rss(cache, name, meta):
    if meta['parser'] == 'npr':
        publication_time = meta.get('publication_time', None)
        if publication_time:
            data = NprParser(cache.raw, name, publication_time=publication_time)
        else:
            data = NprParser(cache.raw, name)
    else:
        raise ValueError(f"unknown parser type {meta['parser']}")

    episodes = []
    for item in data.episodes:
        e = podgen.Episode()
        e.id = escape(item.id)
        e.title = escape(item.title)
        e.media = podgen.Media(item.media_url, item.media_size, duration=datetime.timedelta(seconds=item.media_duration))
        e.publication_date = item.publication_date
        e.link = item.link
        episodes.append(e)

    if 'title' in meta:
        title = meta['title']
    else:
        title = getattr(data, 'title')

    if 'author' in meta:
        author = meta['author']
    else:
        author = getattr(data, 'author', None)

    if 'image' in meta:
        image = meta['image']
    else:
        image = getattr(data, 'image', None)

    if 'description' in meta:
        description = meta['description']
    else:
        description = f"Auto-generated by nrfeed. Data sourced from {meta['url']}. Report issues to https://github.com/pyther/nrfeed/issues"

    category = meta.get('category', None)
    url = meta.get('url', None)

    podcast = podgen.Podcast()
    podcast.name = escape(title)
    podcast.description = escape(description)
    if url:
        podcast.website = url
    if category:
        podcast.category = podgen.Category(category[0], category[1])
    podcast.language = "en-US"
    if author:
        podcast.authors = [podgen.Person(author, None)]
    if image:
        podcast.image = image
    podcast.explicit = False
    podcast.last_updated = pytz.utc.localize(datetime.datetime.fromtimestamp(cache.fetched))
    podcast.generator = "pyther/nrfeed"
    podcast.episodes = episodes
    podcast.publication_date = False

    return podcast.rss_str()


def get_feed_name(id_):
    feeds = get_feeds()

    if id_ in feeds:
        return id_

    if id_.isdigit():
        for key, value in feeds.items():
            if int(id_) == value['id']:
                return key
    raise ValueError


# Check if cache has expired every 10 seconds, serve from cache otherwise
@lru_cache(1)
def feed(name):
    # Return 404 if feed not in feeds.json
    try:
        meta = get_feeds()[name]
    except ValueError:
        abort(404)

    # Load Cache
    cache = Cache(name, CACHE_TIMEOUT)
    cache.load()

    # Retun RSS if cache is valid
    if not cache.is_expired():
        return cache.response()

    # Update cache
    try:
        req = get_source_url(meta['url'])
    except Exception as e:
        app.logger.error(f"connection error: {e}")
        abort(503, 'remote server unavailable')
    else:
        if req.ok:
            cache.set_raw(req.text)
        else:
            app.logger.error(f"status code {req.status_code} from {meta['url']}")
            abort(503, 'request to remote server was unsuccessful')

    # Generate RSS XML
    rss = generate_rss(cache, name, meta)
    app.logger.info(f"generated rss for {name}")
    cache.set_rss(rss)

    # Write cache, close lock, return response
    cache.save()
    return cache.response()


@app.route('/')
@app.route('/index')
def index():
    return render_template('index.html', feeds=get_feeds())


@app.route('/podcast/<_id>')
@app.route('/podcast/<_id>.xml')
def podcast(_id):
    try:
        name = get_feed_name(_id)
    except ValueError:
        abort(404)
    response = feed(name)
    return response
